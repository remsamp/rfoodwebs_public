inter4 <- inter4[idx22, ]
# inter4 <- inter4[inter4$Valid_Aphia == "127141" | inter4$Valid_Aphia ==  "127082" |   inter4$Valid_Aphia ==  "127150" |  inter4$Valid_Aphia ==  "126964" | inter4$Valid_Aphia ==  "127153" |
#                    inter4$Valid_Aphia ==  "127203" |    inter4$Valid_Aphia ==  "126892" |    inter4$Valid_Aphia ==  "127262" |    inter4$Valid_Aphia ==  "127387" |
#                    inter4$Valid_Aphia ==  "127204"  |  inter4$Valid_Aphia ==  "150630" |    inter4$Valid_Aphia ==  "126425" |    inter4$Valid_Aphia ==  "127143", ]
# to work on abundance weighted depth
inter4$haul_id_size <- paste(inter4$haul_id, inter4$propmaxsizeclass, sep = "_")
# abundances are repeated for all entries at same haul_id and size class so can get rid of replicates
inter4 <- inter4[!duplicated(inter4$haul_id_size), ]
# so we have got haul_id, and for each we have certain size classes with newab in it. can we look at correlation
mydf <- data.frame(haul_id = rep(inter4$haul_id, each = 5), myclass = rep(c(1:5), nrow(inter4)))
mydf1 <- data.frame(as.numeric(inter4$newab), inter4$haul_id, inter4$haul_id_size)
mydf1$myclass <- sapply(c(1:nrow(mydf1)), function(i){
bla <- unlist(strsplit(x = as.character(mydf1[i, 3]), split = "_", fixed = T))
bla[length(bla)]
})
mydf$haul_id_size <- paste(mydf$haul_id, mydf$myclass, sep = "_")
mydf$ab <- rep(0, nrow(mydf))
for(uuu in 1:nrow(mydf1)) mydf$ab[mydf$haul_id_size == mydf1$inter4.haul_id_size[uuu]] <- mydf1$as.numeric.inter4.newab.[uuu]
res1 <- c(res1, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "1"]))
res2 <- c(res2, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "2"]))
res3 <- c(res3, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "3"]))
res4 <-c(res4, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "4"]))
}
print(i)
}
# par(mfrow = c(1, 4), mar = c(3, 3, 2, 3))
# plot(rep(c(1993:2013), each = 20), res1, ylim = c(-0.25, 1))
# abline(lm(tapply(res1, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# plot(rep(c(1993:2013), each = 20), res2, ylim = c(-0.25, 1))
# abline(lm(tapply(res2, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# plot(rep(c(1993:2013), each = 20), res3, ylim = c(-0.25, 1))
# abline(lm(tapply(res3, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# plot(rep(c(1993:2013), each = 20), res4, ylim = c(-0.25, 1))
# abline(lm(tapply(res4, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# summary(lm(res1 ~ rep(c(1993:2013), each = 20)))
# summary(lm(res2 ~ rep(c(1993:2013), each = 20)))
# summary(lm(res3 ~ rep(c(1993:2013), each = 20)))
# summary(lm(res4 ~ rep(c(1993:2013), each = 20)))
dat <- data.frame(res1, res2, res3, res4, rep(c(1993:2013), each = 20))
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size1_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size2_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size3_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size4_shallow.Rdata")
save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size5_shallow.Rdata")
as.numeric(inter1$sizespe))
as.numeric(inter1$sizespe)
head(inter1)
tapply(as.numeric(inter1$propmaxsize), list(factor(inter1$propmaxsizeclass), factor(inter1$Year), meanr)
tapply(as.numeric(inter1$propmaxsize), list(factor(inter1$propmaxsizeclass), factor(inter1$Year)), meanr)
sizeintime <- tapply(as.numeric(inter1$propmaxsize), list(factor(inter1$propmaxsizeclass), factor(inter1$Year)), meanr)
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0,1))
plot(sizeintime[2,], pch = 16, ty = "b", ylim = c(0,1))
plot(sizeintime[3,], pch = 16, ty = "b", ylim = c(0,1))
plot(sizeintime[4,], pch = 16, ty = "b", ylim = c(0,1))
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.1,0.2))
plot(sizeintime[2,], pch = 16, ty = "b", ylim = c(0.3, 0.4))
plot(sizeintime[3,], pch = 16, ty = "b", ylim = c(0.5,0.6))
plot(sizeintime[3,], pch = 16, ty = "b", ylim = c(0.45,0.55))
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.1,0.2))
plot(sizeintime[2,], pch = 16, ty = "b", ylim = c(0.3, 0.35))
plot(sizeintime[3,], pch = 16, ty = "b", ylim = c(0.45,0.55))
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.14,0.18))
plot(sizeintime[2,], pch = 16, ty = "b", ylim = c(0.3, 0.32))
plot(sizeintime[3,], pch = 16, ty = "b", ylim = c(0.48,0.5))
plot(sizeintime[4,], pch = 16, ty = "b", ylim = c(0,1))
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.14,0.18))
plot(sizeintime[2,], pch = 16, ty = "b", ylim = c(0.3, 0.32))
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.14,0.18))
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.14,0.18))
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.14,0.18))
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.14,0.18))
plot(sizeintime[2,], pch = 16, ty = "b", ylim = c(0.3, 0.32))
plot(sizeintime[3,], pch = 16, ty = "b", ylim = c(0.48,0.5))
plot(sizeintime[4,], pch = 16, ty = "b", ylim = c(0,1))
plot(sizeintime[4,], pch = 16, ty = "b", ylim = c(0.65,1))
plot(sizeintime[4,], pch = 16, ty = "b", ylim = c(0.67,0.69))
plot(sizeintime[5,], pch = 16, ty = "b", ylim = c(0,1))
plot(sizeintime[5,], pch = 16, ty = "b", ylim = c(0.82,0.84))
plot(sizeintime[5,], pch = 16, ty = "b", ylim = c(0.85,0.87))
plot(sizeintime[5,], pch = 16, ty = "b", ylim = c(0.83,0.85))
plot(sizeintime[5,], pch = 16, ty = "b", ylim = c(0.835,0.855))
par(mfrow = c(1, 5))
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.14,0.18))
plot(sizeintime[2,], pch = 16, ty = "b", ylim = c(0.3, 0.32))
plot(sizeintime[3,], pch = 16, ty = "b", ylim = c(0.48,0.5))
plot(sizeintime[4,], pch = 16, ty = "b", ylim = c(0.67,0.69))
plot(sizeintime[5,], pch = 16, ty = "b", ylim = c(0.835,0.855))
myidx <- paste(inter1$haul_id, inter1$propmaxsizeclass, sep = "_")
tapply(inter1$HLNoAtLngt, list(factor(myidx)), sumr)
tapply(as.numeric(inter1$HLNoAtLngt), list(factor(myidx)), sumr)
tapply(as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr)
tapply(as.numeric(inter1$propmaxsize) * as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr) / tapply(as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr)
tapply(as.numeric(inter1$propmaxsize) * as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr)
rm(list = ls())
library(devtools)
install_github(repo = "remsamp/rfoodwebs", ref = "working_branch", subdir = "rfoodwebs_R_package/Rfoodwebs", auth_token = "6a49e64b00ef3604d38450bc669d70d36a2874b2")
library(Rfoodwebs)
?web_generator_r
web_generator_r
rm(list = ls())
library(devtools)
install_github(repo = "remsamp/rfoodwebs", ref = "working_branch", subdir = "rfoodwebs_R_package/Rfoodwebs", auth_token = "6a49e64b00ef3604d38450bc669d70d36a2874b2")
library(Rfoodwebs)
rm(list = ls())
library(devtools)
install_github(repo = "remsamp/rfoodwebs", ref = "working_branch", subdir = "rfoodwebs_R_package/Rfoodwebs", auth_token = "6a49e64b00ef3604d38450bc669d70d36a2874b2")
library(Rfoodwebs)
web_generator
library(Rfoodwebs)
?web_generator
setwd("/Users/Remi/Google Drive/not_to_share/my_backup/myDocuments/github/rfoodwebs/rfoodwebs_R_package")
setwd("Rfoodwebs")
devtools::document()
rm(list = ls())
library(devtools)
install_github(repo = "remsamp/rfoodwebs", ref = "working_branch", subdir = "rfoodwebs_R_package/Rfoodwebs", auth_token = "6a49e64b00ef3604d38450bc669d70d36a2874b2")
library(Rfoodwebs)
web_generator
library(Rfoodwebs)
?web_generator
web_generator
rm(list = ls())
library(devtools)
install_github(repo = "remsamp/rfoodwebs", ref = "working_branch", subdir = "rfoodwebs_R_package/Rfoodwebs", auth_token = "6a49e64b00ef3604d38450bc669d70d36a2874b2")
library(Rfoodwebs)
?web_generator
rm(list = ls())
setwd("~/Google Drive/not_to_share/my_backup/myDocuments/github/rfoodwebs/rfoodwebs_R_package")
library(devtools)
devtools::install("Rfoodwebs",local=FALSE)
library(Rfoodwebs)
web_generator
setwd("/Users/Remi/Google Drive/not_to_share/my_backup/myDocuments/github/rfoodwebs/rfoodwebs_R_package")
setwd("Rfoodwebs")
devtools::document()# this
?web_generator
?web_generator_r
setwd("/Users/Remi/Google Drive/not_to_share/my_backup/myDocuments/github/rfoodwebs/rfoodwebs_R_package")
setwd("Rfoodwebs")
devtools::document()# t
setwd("/Users/Remi/Google Drive/not_to_share/my_backup/myDocuments/github/rfoodwebs/rfoodwebs_R_package")
setwd("Rfoodwebs")
devtools::document()# t
?web_generator_r
?web_generator
rm(list = ls())
library(devtools)
install_github(repo = "remsamp/rfoodwebs", ref = "working_branch", subdir = "rfoodwebs_R_package/Rfoodwebs", auth_token = "6a49e64b00ef3604d38450bc669d70d36a2874b2")
library(Rfoodwebs)
?web_generator
createcheddarobj
library(Rfoodwebs)
data()
data(package = "Rfoodwebs")
web_generator
rm(list = ls())
rm(list=ls())
list.library <- list("RSQLite", "DBI" , "tidyr", "dplyr", "ggplot2", "ggmap", "RCurl", "XML", "data.table", "robis", "spocc", "spoccutils", "ncdf4", "lubridate", "SSOAP" ,"rfishbase","XMLSchema","rgdal","raster","taxizesoap", "vegan")
sapply (list.library ,function (i) library(i, character.only = T, quietly = T))
load(file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/subset_with_depth.Rdata")
deepspe <- c("126285"  , "127140" ,  "127147" ,  "274304"  , "126448"  , "105876" ,  "126461"  , "126793"  , "126555"  , "127259" ,
"126437" ,  "126450" ,  "126458"  , "126484" ,  "127151"  , "127136" ,"127137"  , "105814"  , "126444" ,  "127146")
mediumspe <- c("126986" ,  "127160"  , "236458"  , "127066", "127139" ,   "127149"  , "126761"  , "105883"  , "127126"  , "126445"  , "105885" ,
" 127156 " , "105887" ,  "126822" ,  "126438"  , "105821"  ,   "150637" ,  "126792"  , "367297",  "126436" ,  "127190" ,  "126996" ,  "126795"  , "127427" ,  "126446")
shallowspe <- c("127141" , "127082" ,  "127150" ,  "126964" ,  "127153" , "127203" ,  "126892" ,  "127262" ,  "127387" ,"127204"  , "150630" ,  "126425" ,  "127143")
sumr <- function(x) sum(x, na.rm = T)
# this next step is getting rid of one haul, so not sure that is ok
inter1 <- inter[-which(inter$Valid_Aphia == "107253"), ]
inter1 <- inter1[-which(inter1$Valid_Aphia == "107254"), ]
inter1 <- inter1[-which(inter1$Valid_Aphia == "107276"), ]
# we want a selection of hauls that is comparable from one year to the next
inter2 <- inter1[!duplicated(inter1$haul_id), ]
size1 <- numeric(0)
size2 <- numeric(0)
size3 <- numeric(0)
size4 <- numeric(0)
size5 <- numeric(0)
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
finalres <- matrix(NA, nrow = 21, ncol = length(sort(unique(inter1$propmaxsizeclass))))
res1 <- numeric(0)
res2 <- numeric(0)
res3 <- numeric(0)
res4 <- numeric(0)
inter1$newab <- inter1$newabdeep
myspelist <- deepspe
inter2 <- inter1[!duplicated(inter1$haul_id), ]
# finalres <- matrix(NA, nrow = 21, ncol = length(sort(unique(inter1$propmaxsizeyearclass))))
for(i in 1993:2013){
# for(j in 1:length(sort(unique(inter2$sizeclass)))){
# i <- 1993
inter3 <- inter2[inter2$Year == as.character(i),]
# & inter2$sizeclass == sort(unique(inter2$sizeclass))[j], ]
inter3 <- inter3[!is.na(inter3$Depth),]
inter3 <- inter3[!is.na(inter3$depthclass),]
inter3$idx <- c(1:nrow(inter3))
topick <- rmultinom(prob = meanprop, size = nrow(inter3), n = 20)
meanvect <- vector("list", 20)
for(u in 1:ncol(topick)){
# u <- 1
# sample the depth classes to obtain a subset of inter3 that is representative of mean depth distribution
meanvect[[u]] <- inter3$haul_id[c(sample(inter3$idx[inter3$depthclass == 15], size = topick[1,u], replace = T),sample(inter3$idx[inter3$depthclass == 25], size = topick[2,u], replace = T),
sample(inter3$idx[inter3$depthclass == 35], size = topick[3,u], replace = T),sample(inter3$idx[inter3$depthclass == 45], size = topick[4,u], replace = T),
sample(inter3$idx[inter3$depthclass == 55], size = topick[5,u], replace = T),sample(inter3$idx[inter3$depthclass == 65], size = topick[6,u], replace = T),
sample(inter3$idx[inter3$depthclass == 75], size = topick[7,u], replace = T))]
}
# this is a list of all picked haul ids. now go back to inter, get all rows that match the haul_ids
# than subset for given species and eliminate duplicate of size classes for a given haul because we
# want the mean depth of the hauls that contain that size class for that species
# res <- rep(0, length(sort(unique(inter1$sizeclass))))
res <- rep(0, length(sort(unique(inter1$propmaxsizeclass))))
# res <- rep(0, length(sort(unique(inter1$propmaxsizeyearclass))))
for(u in 1:ncol(topick))
{
# u <- 1
idx <- meanvect[[u]]
idx1 <- numeric(0)
for(j in 1:length(idx)) idx1 <- c(idx1, which(inter1$haul_id == idx[j]))
inter4 <- inter1[idx1, ]
idx22 <- numeric(0)
for(iii in 1:length(myspelist)) idx22 <- c(idx22, which(inter4$Valid_Aphia == myspelist[iii]))
inter4 <- inter4[idx22, ]
# inter4 <- inter4[inter4$Valid_Aphia == "127141" | inter4$Valid_Aphia ==  "127082" |   inter4$Valid_Aphia ==  "127150" |  inter4$Valid_Aphia ==  "126964" | inter4$Valid_Aphia ==  "127153" |
#                    inter4$Valid_Aphia ==  "127203" |    inter4$Valid_Aphia ==  "126892" |    inter4$Valid_Aphia ==  "127262" |    inter4$Valid_Aphia ==  "127387" |
#                    inter4$Valid_Aphia ==  "127204"  |  inter4$Valid_Aphia ==  "150630" |    inter4$Valid_Aphia ==  "126425" |    inter4$Valid_Aphia ==  "127143", ]
# to work on abundance weighted depth
inter4$haul_id_size <- paste(inter4$haul_id, inter4$propmaxsizeclass, sep = "_")
# abundances are repeated for all entries at same haul_id and size class so can get rid of replicates
inter4 <- inter4[!duplicated(inter4$haul_id_size), ]
# so we have got haul_id, and for each we have certain size classes with newab in it. can we look at correlation
mydf <- data.frame(haul_id = rep(inter4$haul_id, each = 5), myclass = rep(c(1:5), nrow(inter4)))
mydf1 <- data.frame(as.numeric(inter4$newab), inter4$haul_id, inter4$haul_id_size)
mydf1$myclass <- sapply(c(1:nrow(mydf1)), function(i){
bla <- unlist(strsplit(x = as.character(mydf1[i, 3]), split = "_", fixed = T))
bla[length(bla)]
})
mydf$haul_id_size <- paste(mydf$haul_id, mydf$myclass, sep = "_")
mydf$ab <- rep(0, nrow(mydf))
for(uuu in 1:nrow(mydf1)) mydf$ab[mydf$haul_id_size == mydf1$inter4.haul_id_size[uuu]] <- mydf1$as.numeric.inter4.newab.[uuu]
res1 <- c(res1, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "1"]))
res2 <- c(res2, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "2"]))
res3 <- c(res3, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "3"]))
res4 <-c(res4, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "4"]))
}
print(i)
}
inter$Depth[inter$Depth == "-9"] <- NA
# par(mfrow = c(6, 4), mar = c(3,3,2,3))
# for(i in 1993:2013) plot(density(as.numeric(inter$Depth[!duplicated(inter$haul_id) & inter$Year == as.character(i)]), na.rm = T))
prop <- matrix(0, nrow = 21, ncol = 14)
for(i in 1993:2013)prop[i-1992,] <- (hist(as.numeric(inter$Depth[!duplicated(inter$haul_id) & inter$Year == as.character(i)]), plot = F, breaks = seq(0, 140, by =10))$counts)
idx <- which(sapply(c(1:ncol(prop)), function(i) sum(prop[,i]==0)) == 0)
sizeclasslev <- as.character(idx)
prop <- prop[,idx]
for(i in 1:nrow(prop)) prop[i, ] <- prop[i, ] / sum(prop[i, ])
meanprop <- colMeans(prop)
inter$depthclass <- rep(NA, nrow(inter))
inter$depthclass[as.numeric(inter$Depth) > 10 & as.numeric(inter$Depth) <= 20] <- 15
inter$depthclass[as.numeric(inter$Depth) > 20 & as.numeric(inter$Depth) <= 30] <- 25
inter$depthclass[as.numeric(inter$Depth) > 30 & as.numeric(inter$Depth) <= 40] <- 35
inter$depthclass[as.numeric(inter$Depth) > 40 & as.numeric(inter$Depth) <= 50] <- 45
inter$depthclass[as.numeric(inter$Depth) > 50 & as.numeric(inter$Depth) <= 60] <- 55
inter$depthclass[as.numeric(inter$Depth) > 60 & as.numeric(inter$Depth) <= 70] <- 65
inter$depthclass[as.numeric(inter$Depth) > 70 & as.numeric(inter$Depth) <= 80] <- 75
finalres <- matrix(NA, nrow = 21, ncol = length(sort(unique(inter1$propmaxsizeclass))))
res1 <- numeric(0)
res2 <- numeric(0)
res3 <- numeric(0)
res4 <- numeric(0)
inter1$newab <- inter1$newabdeep
myspelist <- deepspe
inter2 <- inter1[!duplicated(inter1$haul_id), ]
# finalres <- matrix(NA, nrow = 21, ncol = length(sort(unique(inter1$propmaxsizeyearclass))))
for(i in 1993:2013){
# for(j in 1:length(sort(unique(inter2$sizeclass)))){
# i <- 1993
inter3 <- inter2[inter2$Year == as.character(i),]
# & inter2$sizeclass == sort(unique(inter2$sizeclass))[j], ]
inter3 <- inter3[!is.na(inter3$Depth),]
inter3 <- inter3[!is.na(inter3$depthclass),]
inter3$idx <- c(1:nrow(inter3))
topick <- rmultinom(prob = meanprop, size = nrow(inter3), n = 20)
meanvect <- vector("list", 20)
for(u in 1:ncol(topick)){
# u <- 1
# sample the depth classes to obtain a subset of inter3 that is representative of mean depth distribution
meanvect[[u]] <- inter3$haul_id[c(sample(inter3$idx[inter3$depthclass == 15], size = topick[1,u], replace = T),sample(inter3$idx[inter3$depthclass == 25], size = topick[2,u], replace = T),
sample(inter3$idx[inter3$depthclass == 35], size = topick[3,u], replace = T),sample(inter3$idx[inter3$depthclass == 45], size = topick[4,u], replace = T),
sample(inter3$idx[inter3$depthclass == 55], size = topick[5,u], replace = T),sample(inter3$idx[inter3$depthclass == 65], size = topick[6,u], replace = T),
sample(inter3$idx[inter3$depthclass == 75], size = topick[7,u], replace = T))]
}
# this is a list of all picked haul ids. now go back to inter, get all rows that match the haul_ids
# than subset for given species and eliminate duplicate of size classes for a given haul because we
# want the mean depth of the hauls that contain that size class for that species
# res <- rep(0, length(sort(unique(inter1$sizeclass))))
res <- rep(0, length(sort(unique(inter1$propmaxsizeclass))))
# res <- rep(0, length(sort(unique(inter1$propmaxsizeyearclass))))
for(u in 1:ncol(topick))
{
# u <- 1
idx <- meanvect[[u]]
idx1 <- numeric(0)
for(j in 1:length(idx)) idx1 <- c(idx1, which(inter1$haul_id == idx[j]))
inter4 <- inter1[idx1, ]
idx22 <- numeric(0)
for(iii in 1:length(myspelist)) idx22 <- c(idx22, which(inter4$Valid_Aphia == myspelist[iii]))
inter4 <- inter4[idx22, ]
# inter4 <- inter4[inter4$Valid_Aphia == "127141" | inter4$Valid_Aphia ==  "127082" |   inter4$Valid_Aphia ==  "127150" |  inter4$Valid_Aphia ==  "126964" | inter4$Valid_Aphia ==  "127153" |
#                    inter4$Valid_Aphia ==  "127203" |    inter4$Valid_Aphia ==  "126892" |    inter4$Valid_Aphia ==  "127262" |    inter4$Valid_Aphia ==  "127387" |
#                    inter4$Valid_Aphia ==  "127204"  |  inter4$Valid_Aphia ==  "150630" |    inter4$Valid_Aphia ==  "126425" |    inter4$Valid_Aphia ==  "127143", ]
# to work on abundance weighted depth
inter4$haul_id_size <- paste(inter4$haul_id, inter4$propmaxsizeclass, sep = "_")
# abundances are repeated for all entries at same haul_id and size class so can get rid of replicates
inter4 <- inter4[!duplicated(inter4$haul_id_size), ]
# so we have got haul_id, and for each we have certain size classes with newab in it. can we look at correlation
mydf <- data.frame(haul_id = rep(inter4$haul_id, each = 5), myclass = rep(c(1:5), nrow(inter4)))
mydf1 <- data.frame(as.numeric(inter4$newab), inter4$haul_id, inter4$haul_id_size)
mydf1$myclass <- sapply(c(1:nrow(mydf1)), function(i){
bla <- unlist(strsplit(x = as.character(mydf1[i, 3]), split = "_", fixed = T))
bla[length(bla)]
})
mydf$haul_id_size <- paste(mydf$haul_id, mydf$myclass, sep = "_")
mydf$ab <- rep(0, nrow(mydf))
for(uuu in 1:nrow(mydf1)) mydf$ab[mydf$haul_id_size == mydf1$inter4.haul_id_size[uuu]] <- mydf1$as.numeric.inter4.newab.[uuu]
res1 <- c(res1, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "1"]))
res2 <- c(res2, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "2"]))
res3 <- c(res3, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "3"]))
res4 <-c(res4, cor(mydf$ab[mydf$myclass == "5"], mydf$ab[mydf$myclass == "4"]))
}
print(i)
}
# par(mfrow = c(1, 4), mar = c(3, 3, 2, 3))
# plot(rep(c(1993:2013), each = 20), res1, ylim = c(-0.25, 1))
# abline(lm(tapply(res1, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# plot(rep(c(1993:2013), each = 20), res2, ylim = c(-0.25, 1))
# abline(lm(tapply(res2, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# plot(rep(c(1993:2013), each = 20), res3, ylim = c(-0.25, 1))
# abline(lm(tapply(res3, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# plot(rep(c(1993:2013), each = 20), res4, ylim = c(-0.25, 1))
# abline(lm(tapply(res4, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# summary(lm(res1 ~ rep(c(1993:2013), each = 20)))
# summary(lm(res2 ~ rep(c(1993:2013), each = 20)))
# summary(lm(res3 ~ rep(c(1993:2013), each = 20)))
# summary(lm(res4 ~ rep(c(1993:2013), each = 20)))
dat <- data.frame(res1, res2, res3, res4, rep(c(1993:2013), each = 20))
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size1_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size2_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size3_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size4_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size5_shallow.Rdata")
# dat <- dat[!is.na(size1),]
# sizeintime <- tapply(as.numeric(inter1$propmaxsize), list(factor(inter1$propmaxsizeclass), factor(inter1$Year)), meanr)
# myidx <- paste(inter1$haul_id, inter1$propmaxsizeclass, sep = "_")
# tapply(as.numeric(inter1$propmaxsize) * as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr) / tapply(as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr)
# apart from the very biggest class it is not clear what is happening in time, calculte with weighted propmaxsizes. I have a feeling that is the
# explanation
par(mfrow = c(1, 5))
plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.14,0.18))
plot(sizeintime[2,], pch = 16, ty = "b", ylim = c(0.3, 0.32))
plot(sizeintime[3,], pch = 16, ty = "b", ylim = c(0.48,0.5))
plot(sizeintime[4,], pch = 16, ty = "b", ylim = c(0.67,0.69))
plot(sizeintime[5,], pch = 16, ty = "b", ylim = c(0.835,0.855))
names(dat) <- c("res1", "res2", "res3", "res4", "myears")
p1 <- ggplot(dat, aes(x = myears, y = res1)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p2 <- ggplot(dat, aes(x = myears, y = res2)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p3 <- ggplot(dat, aes(x = myears, y = res3)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p4 <- ggplot(dat, aes(x = myears, y = res4)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
quartz(height = 3, width = 7)
multiplot(p1, p2, p3, p4, cols=4)
quartz(height = 3, width = 7)
multiplot(p1, p2, p3, p4, cols=4)
quartz(height = 3, width = 7)
multiplot(p1, p2, p3, p4, cols=4)
finalres <- matrix(NA, nrow = 21, ncol = length(sort(unique(inter1$propmaxsizeclass))))
res1 <- numeric(0)
res2 <- numeric(0)
res3 <- numeric(0)
res4 <- numeric(0)
inter1$newab <- inter1$newabdeep
myspelist <- deepspe
inter2 <- inter1[!duplicated(inter1$haul_id), ]
# finalres <- matrix(NA, nrow = 21, ncol = length(sort(unique(inter1$propmaxsizeyearclass))))
for(i in 1993:2013){
# for(j in 1:length(sort(unique(inter2$sizeclass)))){
# i <- 1993
inter3 <- inter2[inter2$Year == as.character(i),]
# & inter2$sizeclass == sort(unique(inter2$sizeclass))[j], ]
inter3 <- inter3[!is.na(inter3$Depth),]
inter3 <- inter3[!is.na(inter3$depthclass),]
inter3$idx <- c(1:nrow(inter3))
topick <- rmultinom(prob = meanprop, size = nrow(inter3), n = 20)
meanvect <- vector("list", 20)
for(u in 1:ncol(topick)){
# u <- 1
# sample the depth classes to obtain a subset of inter3 that is representative of mean depth distribution
meanvect[[u]] <- inter3$haul_id[c(sample(inter3$idx[inter3$depthclass == 15], size = topick[1,u], replace = T),sample(inter3$idx[inter3$depthclass == 25], size = topick[2,u], replace = T),
sample(inter3$idx[inter3$depthclass == 35], size = topick[3,u], replace = T),sample(inter3$idx[inter3$depthclass == 45], size = topick[4,u], replace = T),
sample(inter3$idx[inter3$depthclass == 55], size = topick[5,u], replace = T),sample(inter3$idx[inter3$depthclass == 65], size = topick[6,u], replace = T),
sample(inter3$idx[inter3$depthclass == 75], size = topick[7,u], replace = T))]
}
# this is a list of all picked haul ids. now go back to inter, get all rows that match the haul_ids
# than subset for given species and eliminate duplicate of size classes for a given haul because we
# want the mean depth of the hauls that contain that size class for that species
# res <- rep(0, length(sort(unique(inter1$sizeclass))))
res <- rep(0, length(sort(unique(inter1$propmaxsizeclass))))
# res <- rep(0, length(sort(unique(inter1$propmaxsizeyearclass))))
for(u in 1:ncol(topick))
{
# u <- 1
idx <- meanvect[[u]]
idx1 <- numeric(0)
for(j in 1:length(idx)) idx1 <- c(idx1, which(inter1$haul_id == idx[j]))
inter4 <- inter1[idx1, ]
idx22 <- numeric(0)
for(iii in 1:length(myspelist)) idx22 <- c(idx22, which(inter4$Valid_Aphia == myspelist[iii]))
inter4 <- inter4[idx22, ]
# inter4 <- inter4[inter4$Valid_Aphia == "127141" | inter4$Valid_Aphia ==  "127082" |   inter4$Valid_Aphia ==  "127150" |  inter4$Valid_Aphia ==  "126964" | inter4$Valid_Aphia ==  "127153" |
#                    inter4$Valid_Aphia ==  "127203" |    inter4$Valid_Aphia ==  "126892" |    inter4$Valid_Aphia ==  "127262" |    inter4$Valid_Aphia ==  "127387" |
#                    inter4$Valid_Aphia ==  "127204"  |  inter4$Valid_Aphia ==  "150630" |    inter4$Valid_Aphia ==  "126425" |    inter4$Valid_Aphia ==  "127143", ]
# to work on abundance weighted depth
inter4$haul_id_size <- paste(inter4$haul_id, inter4$propmaxsizeclass, sep = "_")
# abundances are repeated for all entries at same haul_id and size class so can get rid of replicates
inter4 <- inter4[!duplicated(inter4$haul_id_size), ]
# so we have got haul_id, and for each we have certain size classes with newab in it. can we look at correlation
mydf <- data.frame(haul_id = rep(inter4$haul_id, each = 5), myclass = rep(c(1:5), nrow(inter4)))
mydf1 <- data.frame(as.numeric(inter4$newab), inter4$haul_id, inter4$haul_id_size)
mydf1$myclass <- sapply(c(1:nrow(mydf1)), function(i){
bla <- unlist(strsplit(x = as.character(mydf1[i, 3]), split = "_", fixed = T))
bla[length(bla)]
})
mydf$haul_id_size <- paste(mydf$haul_id, mydf$myclass, sep = "_")
mydf$ab <- rep(0, nrow(mydf))
for(uuu in 1:nrow(mydf1)) mydf$ab[mydf$haul_id_size == mydf1$inter4.haul_id_size[uuu]] <- mydf1$as.numeric.inter4.newab.[uuu]
res1 <- c(res1, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "2"]))
res2 <- c(res2, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "3"]))
res3 <- c(res3, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "4"]))
res4 <-c(res4, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "5"]))
}
print(i)
}
# par(mfrow = c(1, 4), mar = c(3, 3, 2, 3))
# plot(rep(c(1993:2013), each = 20), res1, ylim = c(-0.25, 1))
# abline(lm(tapply(res1, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# plot(rep(c(1993:2013), each = 20), res2, ylim = c(-0.25, 1))
# abline(lm(tapply(res2, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# plot(rep(c(1993:2013), each = 20), res3, ylim = c(-0.25, 1))
# abline(lm(tapply(res3, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# plot(rep(c(1993:2013), each = 20), res4, ylim = c(-0.25, 1))
# abline(lm(tapply(res4, factor(rep(c(1993:2013),each = 20)), mean)~c(1993:2013)))
# summary(lm(res1 ~ rep(c(1993:2013), each = 20)))
# summary(lm(res2 ~ rep(c(1993:2013), each = 20)))
# summary(lm(res3 ~ rep(c(1993:2013), each = 20)))
# summary(lm(res4 ~ rep(c(1993:2013), each = 20)))
dat <- data.frame(res1, res2, res3, res4, rep(c(1993:2013), each = 20))
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size1_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size2_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size3_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size4_shallow.Rdata")
# save(dat, file = "~/Google Drive/not_to_share/my_backup/myDocuments/postdoc/MERP_postdoc/dat_size5_shallow.Rdata")
# dat <- dat[!is.na(size1),]
# what is the mean size per haul of a given propmaxsizeclass per year??
# sizeintime <- tapply(as.numeric(inter1$propmaxsize), list(factor(inter1$propmaxsizeclass), factor(inter1$Year)), meanr)
# myidx <- paste(inter1$haul_id, inter1$propmaxsizeclass, sep = "_")
# tapply(as.numeric(inter1$propmaxsize) * as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr) / tapply(as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr)
# apart from the very biggest class it is not clear what is happening in time, calculte with weighted propmaxsizes. I have a feeling that is the
# explanation
# par(mfrow = c(1, 5))
# plot(sizeintime[1,], pch = 16, ty = "b", ylim = c(0.14,0.18))
# plot(sizeintime[2,], pch = 16, ty = "b", ylim = c(0.3, 0.32))
# plot(sizeintime[3,], pch = 16, ty = "b", ylim = c(0.48,0.5))
# plot(sizeintime[4,], pch = 16, ty = "b", ylim = c(0.67,0.69))
# plot(sizeintime[5,], pch = 16, ty = "b", ylim = c(0.835,0.855))
names(dat) <- c("res1", "res2", "res3", "res4", "myears")
p1 <- ggplot(dat, aes(x = myears, y = res1)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p2 <- ggplot(dat, aes(x = myears, y = res2)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p3 <- ggplot(dat, aes(x = myears, y = res3)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p4 <- ggplot(dat, aes(x = myears, y = res4)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
quartz(height = 3, width = 7)
multiplot(p1, p2, p3, p4, cols=4)
att
att <- tapply(as.numeric(inter1$propmaxsize) * as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr) / tapply(as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr)
myidx <- paste(inter1$haul_id, inter1$propmaxsizeclass, sep = "_")
att <- tapply(as.numeric(inter1$propmaxsize) * as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr) / tapply(as.numeric(inter1$HLNoAtLngt), list(factor(inter1$Year),factor(myidx)), sumr)
dim(att)
mean(att[1, ], na.rm = T)
levels(factor(myidx))
