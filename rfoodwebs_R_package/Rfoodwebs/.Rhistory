inter4$haul_id_size <- paste(inter4$haul_id, inter4$propmaxsizeclass, sep = "_")
# abundances are repeated for all entries at same haul_id and size class so can get rid of replicates
inter4 <- inter4[!duplicated(inter4$haul_id_size), ]
# so we have got haul_id, and for each we have certain size classes with newab in it. can we look at correlation
mydf <- data.frame(haul_id = rep(inter4$haul_id, each = 5), myclass = rep(c(1:5), nrow(inter4)))
mydf1 <- data.frame(as.numeric(inter4$newab), inter4$haul_id, inter4$haul_id_size)
mydf1$myclass <- sapply(c(1:nrow(mydf1)), function(i){
bla <- unlist(strsplit(x = as.character(mydf1[i, 3]), split = "_", fixed = T))
bla[length(bla)]
})
mydf$haul_id_size <- paste(mydf$haul_id, mydf$myclass, sep = "_")
mydf$ab <- rep(0, nrow(mydf))
for(uuu in 1:nrow(mydf1)) mydf$ab[mydf$haul_id_size == mydf1$inter4.haul_id_size[uuu]] <- mydf1$as.numeric.inter4.newab.[uuu]
testcor1 <- c(testcor1, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "2"])$p.value)
testcor2 <- c(testcor2, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "3"])$p.value)
testcor3 <- c(testcor3, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "4"])$p.value)
testcor4 <-c(testcor4, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "5"])$p.value)
res1 <- c(res1, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "2"]))
res2 <- c(res2, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "3"]))
res3 <- c(res3, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "4"]))
res4 <-c(res4, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "5"]))
}
print(i)
}
head(inter)
prop <- matrix(0, nrow = 21, ncol = 14)
for(i in 1993:2013)prop[i-1992,] <- (hist(as.numeric(inter$Depth[!duplicated(inter$haul_id) & inter$Year == as.character(i)]), plot = F, breaks = seq(0, 140, by =10))$counts)
idx <- which(sapply(c(1:ncol(prop)), function(i) sum(prop[,i]==0)) == 0)
sizeclasslev <- as.character(idx)
prop <- prop[,idx]
for(i in 1:nrow(prop)) prop[i, ] <- prop[i, ] / sum(prop[i, ])
meanprop <- colMeans(prop)
finalres <- matrix(NA, nrow = 21, ncol = length(sort(unique(inter1$propmaxsizeclass))))
res1 <- numeric(0)
res2 <- numeric(0)
res3 <- numeric(0)
res4 <- numeric(0)
testcor1 <- numeric(0)
testcor2 <- numeric(0)
testcor3 <- numeric(0)
testcor4 <- numeric(0)
inter1$newab <- inter1$newabshallow
myspelist <- shallowspe
inter2 <- inter1[!duplicated(inter1$haul_id), ]
# finalres <- matrix(NA, nrow = 21, ncol = length(sort(unique(inter1$propmaxsizeyearclass))))
for(i in 1993:2013){
# for(j in 1:length(sort(unique(inter2$sizeclass)))){
# i <- 1993
inter3 <- inter2[inter2$Year == as.character(i),]
# & inter2$sizeclass == sort(unique(inter2$sizeclass))[j], ]
inter3 <- inter3[!is.na(inter3$Depth),]
inter3 <- inter3[!is.na(inter3$depthclass),]
inter3$idx <- c(1:nrow(inter3))
topick <- rmultinom(prob = meanprop, size = nrow(inter3), n = 20)
meanvect <- vector("list", 20)
for(u in 1:ncol(topick)){
# u <- 1
# sample the depth classes to obtain a subset of inter3 that is representative of mean depth distribution
meanvect[[u]] <- inter3$haul_id[c(sample(inter3$idx[inter3$depthclass == 15], size = topick[1,u], replace = T),sample(inter3$idx[inter3$depthclass == 25], size = topick[2,u], replace = T),
sample(inter3$idx[inter3$depthclass == 35], size = topick[3,u], replace = T),sample(inter3$idx[inter3$depthclass == 45], size = topick[4,u], replace = T),
sample(inter3$idx[inter3$depthclass == 55], size = topick[5,u], replace = T),sample(inter3$idx[inter3$depthclass == 65], size = topick[6,u], replace = T),
sample(inter3$idx[inter3$depthclass == 75], size = topick[7,u], replace = T))]
}
# this is a list of all picked haul ids. now go back to inter, get all rows that match the haul_ids
# than subset for given species and eliminate duplicate of size classes for a given haul because we
# want the mean depth of the hauls that contain that size class for that species
# res <- rep(0, length(sort(unique(inter1$sizeclass))))
res <- rep(0, length(sort(unique(inter1$propmaxsizeclass))))
# res <- rep(0, length(sort(unique(inter1$propmaxsizeyearclass))))
for(u in 1:ncol(topick))
{
# u <- 1
idx <- meanvect[[u]]
idx1 <- numeric(0)
for(j in 1:length(idx)) idx1 <- c(idx1, which(inter1$haul_id == idx[j]))
inter4 <- inter1[idx1, ]
idx22 <- numeric(0)
for(iii in 1:length(myspelist)) idx22 <- c(idx22, which(inter4$Valid_Aphia == myspelist[iii]))
inter4 <- inter4[idx22, ]
# inter4 <- inter4[inter4$Valid_Aphia == "127141" | inter4$Valid_Aphia ==  "127082" |   inter4$Valid_Aphia ==  "127150" |  inter4$Valid_Aphia ==  "126964" | inter4$Valid_Aphia ==  "127153" |
#                    inter4$Valid_Aphia ==  "127203" |    inter4$Valid_Aphia ==  "126892" |    inter4$Valid_Aphia ==  "127262" |    inter4$Valid_Aphia ==  "127387" |
#                    inter4$Valid_Aphia ==  "127204"  |  inter4$Valid_Aphia ==  "150630" |    inter4$Valid_Aphia ==  "126425" |    inter4$Valid_Aphia ==  "127143", ]
# to work on abundance weighted depth
inter4$haul_id_size <- paste(inter4$haul_id, inter4$propmaxsizeclass, sep = "_")
# abundances are repeated for all entries at same haul_id and size class so can get rid of replicates
inter4 <- inter4[!duplicated(inter4$haul_id_size), ]
# so we have got haul_id, and for each we have certain size classes with newab in it. can we look at correlation
mydf <- data.frame(haul_id = rep(inter4$haul_id, each = 5), myclass = rep(c(1:5), nrow(inter4)))
mydf1 <- data.frame(as.numeric(inter4$newab), inter4$haul_id, inter4$haul_id_size)
mydf1$myclass <- sapply(c(1:nrow(mydf1)), function(i){
bla <- unlist(strsplit(x = as.character(mydf1[i, 3]), split = "_", fixed = T))
bla[length(bla)]
})
mydf$haul_id_size <- paste(mydf$haul_id, mydf$myclass, sep = "_")
mydf$ab <- rep(0, nrow(mydf))
for(uuu in 1:nrow(mydf1)) mydf$ab[mydf$haul_id_size == mydf1$inter4.haul_id_size[uuu]] <- mydf1$as.numeric.inter4.newab.[uuu]
testcor1 <- c(testcor1, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "2"])$p.value)
testcor2 <- c(testcor2, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "3"])$p.value)
testcor3 <- c(testcor3, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "4"])$p.value)
testcor4 <-c(testcor4, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "5"])$p.value)
res1 <- c(res1, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "2"]))
res2 <- c(res2, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "3"]))
res3 <- c(res3, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "4"]))
res4 <-c(res4, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "5"]))
}
print(i)
}
class(testcor1)
length(testcor1)
20*21
testcor1
sum(testcor1<0.05)
sum(testcor2<0.05)
sum(testcor3<0.05)
sum(testcor2<0.05)
sum(testcor4<0.05)
dat <- data.frame(res1, res2, res3, res4, testcor1, testcor2, testcor3, testco4,rep(c(1993:2013), each = 20))
dat <- data.frame(res1, res2, res3, res4, testcor1, testcor2, testcor3, testcor4,rep(c(1993:2013), each = 20))
names(dat) <- c("res1", "res2", "res3", "res4", "testcor1", "testcor2", "testcor3", "testcor4", "myears")
p1 <- ggplot(dat, aes(x = myears, y = res1)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p2 <- ggplot(dat, aes(x = myears, y = res2)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p3 <- ggplot(dat, aes(x = myears, y = res3)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p4 <- ggplot(dat, aes(x = myears, y = res4)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
names(dat) <- c("res1", "res2", "res3", "res4", "testcor1", "testcor2", "testcor3", "testcor4", "myears")
dat$testcor1[dat$testcor1 < 0.05] <- 36
dat$testcor1[dat$testcor1 < 1] <- 0
dat$testcor1[dat$testcor1 == 36] <- 1
p1 <- ggplot(dat, aes(x = myears, y = res1, alpha = testcor1)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
dat$testcor2[dat$testcor2 < 0.05] <- 36
dat$testcor2[dat$testcor2 < 1] <- 0
dat$testcor2[dat$testcor2 == 36] <- 1
dat$testcor3[dat$testcor3 < 0.05] <- 36
dat$testcor3[dat$testcor3 < 1] <- 0
dat$testcor3[dat$testcor3 == 36] <- 1
dat$testcor4[dat$testcor4 < 0.05] <- 36
dat$testcor4[dat$testcor4 < 1] <- 0
dat$testcor4[dat$testcor4 == 36] <- 1
p1 <- ggplot(dat, aes(x = myears, y = res1, alpha = testcor1)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p2 <- ggplot(dat, aes(x = myears, y = res2, alpha = testcor2)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p3 <- ggplot(dat, aes(x = myears, y = res3, alpha = testcor3)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p4 <- ggplot(dat, aes(x = myears, y = res4, alpha = testcor4)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
quartz(height = 3, width = 7)
multiplot(p1, p2, p3, p4, cols=4)
testcor1
dat <- data.frame(res1, res2, res3, res4, testcor1, testcor2, testcor3, testcor4,rep(c(1993:2013), each = 20))
names(dat) <- c("res1", "res2", "res3", "res4", "testcor1", "testcor2", "testcor3", "testcor4", "myears")
dat$testcor1[dat$testcor1 < 0.05] <- 36
dat$testcor1[dat$testcor1 < 1] <- 0
dat$testcor1[dat$testcor1 == 36] <- 1
dat$testcor2[dat$testcor2 < 0.05] <- 36
dat$testcor2[dat$testcor2 < 1] <- 0
dat$testcor2[dat$testcor2 == 36] <- 1
dat$testcor3[dat$testcor3 < 0.05] <- 36
dat$testcor3[dat$testcor3 < 1] <- 0
dat$testcor3[dat$testcor3 == 36] <- 1
dat$testcor4[dat$testcor4 < 0.05] <- 36
dat$testcor4[dat$testcor4 < 1] <- 0
dat$testcor4[dat$testcor4 == 36] <- 1
head(dat)
p1 <- ggplot(dat, aes(x = myears, y = res1)) + geom_point(dat, aes(alpha = testcor1)) + geom_smooth() + ylim(-0.25, 1)
?geom_point
plot(dat$myears, dat$res1, col = dat$testcor1)
plot(dat$myears, dat$res1, col = dat$testcor1 + 1)
plot(dat$myears, dat$res1, col = dat$testcor1 + 1)
plot(dat$myears, dat$res1, col = dat$testcor1 + 1)
plot(dat$myears, dat$res1, col = dat$testcor1 + 1)
plot(dat$myears, dat$res1, col = dat$testcor1 + 1)
plot(dat$myears, dat$res2, col = dat$testcor2 + 1)
plot(dat$myears, dat$res3, col = dat$testcor3 + 1)
plot(dat$myears, dat$res4, col = dat$testcor4 + 1)
finalres <- matrix(NA, nrow = 21, ncol = length(sort(unique(inter1$propmaxsizeclass))))
res1 <- numeric(0)
res2 <- numeric(0)
res3 <- numeric(0)
res4 <- numeric(0)
testcor1 <- numeric(0)
testcor2 <- numeric(0)
testcor3 <- numeric(0)
testcor4 <- numeric(0)
inter1$newab <- inter1$newabshallow
myspelist <- shallowspe
inter2 <- inter1[!duplicated(inter1$haul_id), ]
# finalres <- matrix(NA, nrow = 21, ncol = length(sort(unique(inter1$propmaxsizeyearclass))))
for(i in 1993:2013){
# for(j in 1:length(sort(unique(inter2$sizeclass)))){
# i <- 1993
inter3 <- inter2[inter2$Year == as.character(i),]
# & inter2$sizeclass == sort(unique(inter2$sizeclass))[j], ]
inter3 <- inter3[!is.na(inter3$Depth),]
inter3 <- inter3[!is.na(inter3$depthclass),]
inter3$idx <- c(1:nrow(inter3))
nbtopick <- 100
topick <- rmultinom(prob = meanprop, size = nrow(inter3), n = nbtopick)
meanvect <- vector("list", nbtopick)
for(u in 1:ncol(topick)){
# u <- 1
# sample the depth classes to obtain a subset of inter3 that is representative of mean depth distribution
meanvect[[u]] <- inter3$haul_id[c(sample(inter3$idx[inter3$depthclass == 15], size = topick[1,u], replace = T),sample(inter3$idx[inter3$depthclass == 25], size = topick[2,u], replace = T),
sample(inter3$idx[inter3$depthclass == 35], size = topick[3,u], replace = T),sample(inter3$idx[inter3$depthclass == 45], size = topick[4,u], replace = T),
sample(inter3$idx[inter3$depthclass == 55], size = topick[5,u], replace = T),sample(inter3$idx[inter3$depthclass == 65], size = topick[6,u], replace = T),
sample(inter3$idx[inter3$depthclass == 75], size = topick[7,u], replace = T))]
}
# this is a list of all picked haul ids. now go back to inter, get all rows that match the haul_ids
# than subset for given species and eliminate duplicate of size classes for a given haul because we
# want the mean depth of the hauls that contain that size class for that species
# res <- rep(0, length(sort(unique(inter1$sizeclass))))
res <- rep(0, length(sort(unique(inter1$propmaxsizeclass))))
# res <- rep(0, length(sort(unique(inter1$propmaxsizeyearclass))))
for(u in 1:ncol(topick))
{
# u <- 1
idx <- meanvect[[u]]
idx1 <- numeric(0)
for(j in 1:length(idx)) idx1 <- c(idx1, which(inter1$haul_id == idx[j]))
inter4 <- inter1[idx1, ]
idx22 <- numeric(0)
for(iii in 1:length(myspelist)) idx22 <- c(idx22, which(inter4$Valid_Aphia == myspelist[iii]))
inter4 <- inter4[idx22, ]
# inter4 <- inter4[inter4$Valid_Aphia == "127141" | inter4$Valid_Aphia ==  "127082" |   inter4$Valid_Aphia ==  "127150" |  inter4$Valid_Aphia ==  "126964" | inter4$Valid_Aphia ==  "127153" |
#                    inter4$Valid_Aphia ==  "127203" |    inter4$Valid_Aphia ==  "126892" |    inter4$Valid_Aphia ==  "127262" |    inter4$Valid_Aphia ==  "127387" |
#                    inter4$Valid_Aphia ==  "127204"  |  inter4$Valid_Aphia ==  "150630" |    inter4$Valid_Aphia ==  "126425" |    inter4$Valid_Aphia ==  "127143", ]
# to work on abundance weighted depth
inter4$haul_id_size <- paste(inter4$haul_id, inter4$propmaxsizeclass, sep = "_")
# abundances are repeated for all entries at same haul_id and size class so can get rid of replicates
inter4 <- inter4[!duplicated(inter4$haul_id_size), ]
# so we have got haul_id, and for each we have certain size classes with newab in it. can we look at correlation
mydf <- data.frame(haul_id = rep(inter4$haul_id, each = 5), myclass = rep(c(1:5), nrow(inter4)))
mydf1 <- data.frame(as.numeric(inter4$newab), inter4$haul_id, inter4$haul_id_size)
mydf1$myclass <- sapply(c(1:nrow(mydf1)), function(i){
bla <- unlist(strsplit(x = as.character(mydf1[i, 3]), split = "_", fixed = T))
bla[length(bla)]
})
mydf$haul_id_size <- paste(mydf$haul_id, mydf$myclass, sep = "_")
mydf$ab <- rep(0, nrow(mydf))
for(uuu in 1:nrow(mydf1)) mydf$ab[mydf$haul_id_size == mydf1$inter4.haul_id_size[uuu]] <- mydf1$as.numeric.inter4.newab.[uuu]
testcor1 <- c(testcor1, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "2"])$p.value)
testcor2 <- c(testcor2, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "3"])$p.value)
testcor3 <- c(testcor3, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "4"])$p.value)
testcor4 <-c(testcor4, cor.test(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "5"])$p.value)
res1 <- c(res1, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "2"]))
res2 <- c(res2, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "3"]))
res3 <- c(res3, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "4"]))
res4 <-c(res4, cor(mydf$ab[mydf$myclass == "1"], mydf$ab[mydf$myclass == "5"]))
}
print(i)
}
dat <- data.frame(res1, res2, res3, res4, testcor1, testcor2, testcor3, testcor4,rep(c(1993:2013), each = nbtopick))
mylist <- (levels(factor(myidx)) %>% strsplit(split = ""))
mylist <- unlist(sapply(c(1:length(mylist)), function(i) {
x <- length(mylist[[i]])
mylist[[i]][x]}))
mylist1 <- (levels(factor(myidx)) %>% strsplit(split = ""))
mylist1 <- unlist(sapply(c(1:length(mylist1)), function(i) {
x <- length(mylist1[[i]])
paste0(mylist1[[i]][(x-5):(x-2)], collapse = "")}))
endres <- matrix(0, nrow = 21, ncol = 5)
for(i in 1993:2013){
for(j in 1:5){
endres[i-1992, j] <- mean(att[i-1992, which(mylist == as.character(j) & mylist1 == as.character(i))])}}
# apart from the very biggest class it is not clear what is happening in time, calculte with weighted propmaxsizes. I have a feeling that is the
# explanation
par(mfrow = c(1, 5))
plot(endres[,1], pch = 16, ty = "b")
plot(endres[,2], pch = 16, ty = "b")
plot(endres[,3], pch = 16, ty = "b")
plot(endres[,4], pch = 16, ty = "b")
plot(endres[,5], pch = 16, ty = "b")
names(dat) <- c("res1", "res2", "res3", "res4", "testcor1", "testcor2", "testcor3", "testcor4", "myears")
dat$testcor1[dat$testcor1 < 0.05] <- 36
dat$testcor1[dat$testcor1 < 1] <- 0
dat$testcor1[dat$testcor1 == 36] <- 1
dat$testcor2[dat$testcor2 < 0.05] <- 36
dat$testcor2[dat$testcor2 < 1] <- 0
dat$testcor2[dat$testcor2 == 36] <- 1
dat$testcor3[dat$testcor3 < 0.05] <- 36
dat$testcor3[dat$testcor3 < 1] <- 0
dat$testcor3[dat$testcor3 == 36] <- 1
dat$testcor4[dat$testcor4 < 0.05] <- 36
dat$testcor4[dat$testcor4 < 1] <- 0
dat$testcor4[dat$testcor4 == 36] <- 1
p1 <- ggplot(dat, aes(x = myears, y = res1)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p2 <- ggplot(dat, aes(x = myears, y = res2)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p3 <- ggplot(dat, aes(x = myears, y = res3)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p4 <- ggplot(dat, aes(x = myears, y = res4)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
quartz(height = 3, width = 7)
multiplot(p1, p2, p3, p4, cols=4)
plot(dat$myears, dat$res1, col = dat$testcor1 + 1)
par(mfrow = c(1, 4), mar = c(3, 3, 2, 3))
plot(dat$myears, dat$res1, col = dat$testcor1 + 1)
plot(dat$myears, dat$res2, col = dat$testcor2 + 1)
plot(dat$myears, dat$res3, col = dat$testcor3 + 1)
plot(dat$myears, dat$res4, col = dat$testcor4 + 1)
p1 <- ggplot(dat, aes(x = myears, y = res1)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p2 <- ggplot(dat, aes(x = myears, y = res2)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p3 <- ggplot(dat, aes(x = myears, y = res3)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
p4 <- ggplot(dat, aes(x = myears, y = res4)) + geom_point() + geom_smooth() + ylim(-0.25, 1)
quartz(height = 3, width = 7)
multiplot(p1, p2, p3, p4, cols=4)
par(mfrow = c(1, 5))
plot(endres[,1], pch = 16, ty = "b")
plot(endres[,2], pch = 16, ty = "b")
plot(endres[,3], pch = 16, ty = "b")
plot(endres[,4], pch = 16, ty = "b")
plot(endres[,5], pch = 16, ty = "b")
quartz(height = 3, width = 7)
par(mfrow = c(1, 5), mar = c(3,3,2,3))
plot(endres[,1], pch = 16, ty = "b")
plot(endres[,2], pch = 16, ty = "b")
plot(endres[,3], pch = 16, ty = "b")
plot(endres[,4], pch = 16, ty = "b")
plot(endres[,5], pch = 16, ty = "b")
quartz(height = 3, width = 7)
par(mfrow = c(1, 5), mar = c(3,3,2,1))
plot(endres[,1], pch = 16, ty = "b")
plot(endres[,2], pch = 16, ty = "b")
plot(endres[,3], pch = 16, ty = "b")
plot(endres[,4], pch = 16, ty = "b")
plot(endres[,5], pch = 16, ty = "b")
shallowspe
list.library <- c("RSQLite", "DBI" , "dplyr") # "RODBC",
sapply (c(1:length(list.library)) ,function (i) library(list.library[i],character.only=T))
statement <- "select Pred, Pred_Length,Size_category,Mean_Length, Pred_Weight,PRED_ID,Prey, Prey_number, Prey_Length,Indprey_wgt,Ind_prey_vol, MIN_NUM,Shot_Lat_Deg, Shot_Long_Deg, YEAR, Date,Sea, ICES_Rectangle,Division from correctedDAPSTOM join HAULS on DAPSTOM_haul= HAUL_ID"
xx <- dbGetQuery(con,statement)
con <- dbConnect(RSQLite::SQLite(), "~/Google Drive/not_to_share/my_backup/myDocuments/MERP/merp_fish_cefas.sqlite")# ":memory:")
statement <- "select Pred, Pred_Length,Size_category,Mean_Length, Pred_Weight,PRED_ID,Prey, Prey_number, Prey_Length,Indprey_wgt,Ind_prey_vol, MIN_NUM,Shot_Lat_Deg, Shot_Long_Deg, YEAR, Date,Sea, ICES_Rectangle,Division from correctedDAPSTOM join HAULS on DAPSTOM_haul= HAUL_ID"
xx <- dbGetQuery(con,statement)
dat <- xx %>% filter(Sea == "Irish Sea")
statement <- "select * from PREY"
preytab <- dbGetQuery(con,statement)
statement <- "select * from PREDATOR"
predtab <- dbGetQuery(con,statement)
dat$prey_valid <- preytab$VALID_NAME[match(dat$Prey,preytab$Prey)]
dat$prey_latin <- preytab$LATIN[match(dat$Prey,preytab$Prey)]
dat$prey_group <- preytab$GROUP[match(dat$Prey,preytab$Prey)]
meanr <- function(x) mean(x, na.rm = T)
head(predtab)
head(preytab)
codes <- c("127141" , "127082" ,  "127150" ,  "126964" ,  "127153" , "127203" ,  "126892" ,  "127262" ,  "127387" ,"127204"  , "150630" ,  "126425" ,  "127143")
whichspe <- character(0)
idx <- numeric(0)
for(i in 1:length(codes)) whichspe <- c(whichspe, predtab$PRED[which(predtab$APHIA_ID == codes[i])])
for(i in 1:length(whichspe)) idx <- c(idx, which(dat$Pred == whichspe[i]))
dat <- dat[idx, ]
dat$Pred_Length <- as.numeric(dat$Pred_Length)
dat <- dat[!is.na(dat$Pred_Length), ]
maxr <- function(x) max(x, na.rm = T)
max_sizes <- tapply(dat$Pred_Length, factor(dat$Pred), maxr)
dat$max_sizes <- rep(0, nrow(dat))
for(i in 1:length(max_sizes)) dat$max_sizes[dat$Pred == names(max_sizes)[i]] <- max_sizes[i]
dat$prop_size <- dat$Pred_Length / dat$max_sizes
head(dat)
small_dat <- dat[dat$prop_size > 0 & dat$prop_size <= 0.2, ]
small_dat$MIN_NUM <- as.numeric(small_dat$MIN_NUM)
small_dat <- small_dat[!is.na(small_dat$MIN_NUM),]
small_dat$YEAR <- as.numeric(small_dat$YEAR)
small_dat$myear <- rep(0, nrow(small_dat))
small_dat$myear[small_dat$YEAR < 2005] <- "old"
small_dat$myear[small_dat$YEAR >= 2005] <- "recent"
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_valid), factor(small_dat$myear)), sumr)
small_dat
small_dat <- dat[dat$prop_size > 0 & dat$prop_size <= 0.25, ]
small_dat$MIN_NUM <- as.numeric(small_dat$MIN_NUM)
small_dat <- small_dat[!is.na(small_dat$MIN_NUM),]
small_dat$YEAR <- as.numeric(small_dat$YEAR)
small_dat$myear <- rep(0, nrow(small_dat))
small_dat$myear[small_dat$YEAR < 2005] <- "old"
small_dat$myear[small_dat$YEAR >= 2005] <- "recent"
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_valid), factor(small_dat$myear)), sumr)
small_dat
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_valid), factor(small_dat$YEAR)), sumr)
small_dat <- dat[dat$prop_size > 0.5, ]
small_dat <- dat[dat$prop_size > 0.2, ]
small_dat$MIN_NUM <- as.numeric(small_dat$MIN_NUM)
small_dat <- small_dat[!is.na(small_dat$MIN_NUM),]
small_dat$YEAR <- as.numeric(small_dat$YEAR)
small_dat$myear <- rep(0, nrow(small_dat))
small_dat$myear[small_dat$YEAR < 2005] <- "old"
small_dat$myear[small_dat$YEAR >= 2005] <- "recent"
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_valid), factor(small_dat$YEAR)), sumr)
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_valid), factor(small_dat$myear)), sumr)
con <- dbConnect(RSQLite::SQLite(), "~/Google Drive/not_to_share/my_backup/myDocuments/MERP/merp_fish_cefas.sqlite")# ":memory:")
statement <- "select Pred, Pred_Length,Size_category,Mean_Length, Pred_Weight,PRED_ID,Prey, Prey_number, Prey_Length,Indprey_wgt,Ind_prey_vol, MIN_NUM,Shot_Lat_Deg, Shot_Long_Deg, YEAR, Date,Sea, ICES_Rectangle,Division from correctedDAPSTOM join HAULS on DAPSTOM_haul= HAUL_ID"
xx <- dbGetQuery(con,statement)
# separate between before and after 2005 and try to find differences in diet for a subgoup of species as in fish temperature
dat <- xx %>% filter(Sea == "North Sea")
statement <- "select * from PREY"
preytab <- dbGetQuery(con,statement)
statement <- "select * from PREDATOR"
predtab <- dbGetQuery(con,statement)
dat$prey_valid <- preytab$VALID_NAME[match(dat$Prey,preytab$Prey)]
dat$prey_latin <- preytab$LATIN[match(dat$Prey,preytab$Prey)]
dat$prey_group <- preytab$GROUP[match(dat$Prey,preytab$Prey)]
meanr <- function(x) mean(x, na.rm = T)
codes <- c("127141" , "127082" ,  "127150" ,  "126964" ,  "127153" , "127203" ,  "126892" ,  "127262" ,  "127387" ,"127204"  , "150630" ,  "126425" ,  "127143")
whichspe <- character(0)
idx <- numeric(0)
for(i in 1:length(codes)) whichspe <- c(whichspe, predtab$PRED[which(predtab$APHIA_ID == codes[i])])
for(i in 1:length(whichspe)) idx <- c(idx, which(dat$Pred == whichspe[i]))
dat <- dat[idx, ]
dat$Pred_Length <- as.numeric(dat$Pred_Length)
dat <- dat[!is.na(dat$Pred_Length), ]
maxr <- function(x) max(x, na.rm = T)
max_sizes <- tapply(dat$Pred_Length, factor(dat$Pred), maxr)
dat$max_sizes <- rep(0, nrow(dat))
for(i in 1:length(max_sizes)) dat$max_sizes[dat$Pred == names(max_sizes)[i]] <- max_sizes[i]
dat$prop_size <- dat$Pred_Length / dat$max_sizes
small_dat <- dat[dat$prop_size > 0.2 & dat$prop_size <= 0.4, ]
small_dat$MIN_NUM <- as.numeric(small_dat$MIN_NUM)
small_dat <- small_dat[!is.na(small_dat$MIN_NUM),]
small_dat$YEAR <- as.numeric(small_dat$YEAR)
small_dat$myear <- rep(0, nrow(small_dat))
small_dat$myear[small_dat$YEAR < 2005] <- "old"
small_dat$myear[small_dat$YEAR >= 2005] <- "recent"
tapply(small_dat$Pred_Length * small_dat$MIN_NUM, factor(small_dat$myear), sumr) / tapply(small_dat$MIN_NUM, factor(small_dat$myear), sumr)
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_valid), factor(small_dat$YEAR)), sumr)
small_dat <- dat[dat$prop_size > 0.5, ]
small_dat$MIN_NUM <- as.numeric(small_dat$MIN_NUM)
small_dat <- small_dat[!is.na(small_dat$MIN_NUM),]
small_dat$YEAR <- as.numeric(small_dat$YEAR)
small_dat$myear <- rep(0, nrow(small_dat))
small_dat$myear[small_dat$YEAR < 2005] <- "old"
small_dat$myear[small_dat$YEAR >= 2005] <- "recent"
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_valid), factor(small_dat$YEAR)), sumr)
head(small_dat)
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_group), factor(small_dat$YEAR)), sumr)
small_dat$myear[small_dat$YEAR < 2004] <- "old"
small_dat$myear[small_dat$YEAR >= 2004] <- "recent"
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_group), factor(small_dat$myear)), sumr)
con <- dbConnect(RSQLite::SQLite(), "~/Google Drive/not_to_share/my_backup/myDocuments/MERP/merp_fish_cefas.sqlite")# ":memory:")
statement <- "select Pred, Pred_Length,Size_category,Mean_Length, Pred_Weight,PRED_ID,Prey, Prey_number, Prey_Length,Indprey_wgt,Ind_prey_vol, MIN_NUM,Shot_Lat_Deg, Shot_Long_Deg, YEAR, Date,Sea, ICES_Rectangle,Division from correctedDAPSTOM join HAULS on DAPSTOM_haul= HAUL_ID"
xx <- dbGetQuery(con,statement)
# separate between before and after 2005 and try to find differences in diet for a subgoup of species as in fish temperature
dat <- xx %>% filter(Sea == "Irish Sea")
statement <- "select * from PREY"
preytab <- dbGetQuery(con,statement)
statement <- "select * from PREDATOR"
predtab <- dbGetQuery(con,statement)
dat$prey_valid <- preytab$VALID_NAME[match(dat$Prey,preytab$Prey)]
dat$prey_latin <- preytab$LATIN[match(dat$Prey,preytab$Prey)]
dat$prey_group <- preytab$GROUP[match(dat$Prey,preytab$Prey)]
meanr <- function(x) mean(x, na.rm = T)
# codes are same as shallowspe in fish_temperature.R
codes <- c("127141" , "127082" ,  "127150" ,  "126964" ,  "127153" , "127203" ,  "126892" ,  "127262" ,  "127387" ,"127204"  , "150630" ,  "126425" ,  "127143")
whichspe <- character(0)
idx <- numeric(0)
for(i in 1:length(codes)) whichspe <- c(whichspe, predtab$PRED[which(predtab$APHIA_ID == codes[i])])
for(i in 1:length(whichspe)) idx <- c(idx, which(dat$Pred == whichspe[i]))
dat <- dat[idx, ]
dat$Pred_Length <- as.numeric(dat$Pred_Length)
dat <- dat[!is.na(dat$Pred_Length), ]
maxr <- function(x) max(x, na.rm = T)
max_sizes <- tapply(dat$Pred_Length, factor(dat$Pred), maxr)
dat$max_sizes <- rep(0, nrow(dat))
for(i in 1:length(max_sizes)) dat$max_sizes[dat$Pred == names(max_sizes)[i]] <- max_sizes[i]
dat$prop_size <- dat$Pred_Length / dat$max_sizes
small_dat <- dat[dat$prop_size > 0.2 & dat$prop_size <= 0.6, ]
small_dat$MIN_NUM <- as.numeric(small_dat$MIN_NUM)
small_dat <- small_dat[!is.na(small_dat$MIN_NUM),]
small_dat$YEAR <- as.numeric(small_dat$YEAR)
small_dat$myear <- rep(0, nrow(small_dat))
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_group), factor(small_dat$YEAR)), sumr)
small_dat$myear[small_dat$YEAR < 2004] <- "old"
small_dat$myear[small_dat$YEAR >= 2004] <- "recent"
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_group), factor(small_dat$YEAR)), sumr)
tapply(small_dat$MIN_NUM, list(factor(small_dat$prey_group), factor(small_dat$myear)), sumr)
setwd("/Users/Remi/Google Drive/not_to_share/my_backup/myDocuments/github/rfoodwebs/rfoodwebs_R_package")
setwd("Rfoodwebs")
devtools::document()# this works as long as we are in the right folder for the R package, no need to "point" at the R file. the first sentence is the title of the help file, so keep that in mind
install_github(repo = "remsamp/rfoodwebs", ref = "master", subdir = "rfoodwebs_R_package/Rfoodwebs", auth_token = "6a49e64b00ef3604d38450bc669d70d36a2874b2")
library(devtools)
install_github(repo = "remsamp/rfoodwebs", ref = "master", subdir = "rfoodwebs_R_package/Rfoodwebs", auth_token = "6a49e64b00ef3604d38450bc669d70d36a2874b2")
web_generator
install_github(repo = "remsamp/rfoodwebs", ref = "master", subdir = "rfoodwebs_R_package/Rfoodwebs", auth_token = "6a49e64b00ef3604d38450bc669d70d36a2874b2")
web_generator
?web_generator
setwd("/Users/Remi/Google Drive/not_to_share/my_backup/myDocuments/github/rfoodwebs/rfoodwebs_R_package")
setwd("Rfoodwebs")
devtools::document()
rm(list = ls())
library(devtools)
install_github(repo = "remsamp/rfoodwebs", ref = "master", subdir = "rfoodwebs_R_package/Rfoodwebs", auth_token = "6a49e64b00ef3604d38450bc669d70d36a2874b2")
?web_generator
web_generator
?web_generator
